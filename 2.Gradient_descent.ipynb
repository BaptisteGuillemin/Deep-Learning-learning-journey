{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXH1gvO_vQk-"
   },
   "source": [
    " # **Logistic Regression and Gradient Descent in Neural Networks**\n",
    "\n",
    " Logistic regression is a simple form of a neural network that classifies data categorically. \n",
    "The goal of a good logistic regression algorithm is to reduce loss or optimize weights by improving the correctness of the output and this is achieved by a function called **Gradient Descent**. As seen in the course, a good way to evaluate the performance of the logistic regression algorithm is by achieving a minimal cost function (loss function) . Cost function quantifies the error between the predicted value and the expected values. Therefore, a logistic regression model must contain all these functions and we will code out these functions in python.\n",
    "\n",
    "Your task is to build a logistic regression classifier to recognize image if it contains a cat or not. This project is your first step toward deep learning \n",
    "\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "To build your NN, you need to follow the prinicipal steps:\n",
    "\n",
    "- Implement a function for Initializing parameters( weights and bias)\n",
    "- Implement a function for Calculating the loss function and its gradient\n",
    "- Implement a function for the optimization algorithm applying the gradient descent method\n",
    "- Gather all three functions above into a main model function, in the right order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4Jm3t426PiM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPgOKuAg1WrN"
   },
   "source": [
    "First, letâ€™s import all the packages that we will be needing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c9tobv6Y1YuF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import h5py\n",
    "#from lr_utils import load_dataset\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gN4xk-mz1qbc"
   },
   "source": [
    "Second, Download the dataset of images, and put it in data structure\n",
    "Please, get the dataset of training and testing using these commands \n",
    "\n",
    "\n",
    "```\n",
    "!wget -q https://raw.githubusercontent.com/mymehio/test/master/train_catvnoncat.h5\n",
    "!wget -q https://raw.githubusercontent.com/mymehio/test/master/test_catvnoncat.h5\n",
    "```\n",
    "\n",
    "Then, define a function to load them properly into corresponding matrices \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9G20VMXe2Hry"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://raw.githubusercontent.com/mymehio/test/master/train_catvnoncat.h5\n",
    "!wget -q https://raw.githubusercontent.com/mymehio/test/master/test_catvnoncat.h5\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set of images  \n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test of images\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Y4vzwGr4djJ"
   },
   "source": [
    "**Description of the Dataset**\n",
    " \n",
    " \n",
    " Dataset files\".h5\"  contain:\n",
    "\n",
    "- a training set of train images labeled as cat (y=1) or non-cat (y=0)\n",
    "- a test set of test images labeled as cat or non-cat\n",
    "- each image is of shape (num_pxas hieght , num_px as width, 3) where 3 is for the 3 channels (RGB). Thus, each image is square \n",
    "\n",
    "\n",
    "\n",
    "Now, Using the function load_dataset, you have to load matrices into variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Mt3lHjx5OIv"
   },
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1637772687708,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "wrd1tLEj-dcg",
    "outputId": "aa5914fc-a072-4e2c-9a23-4372674eeb6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 64, 64, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_x_orig.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThkMSZSO551Z"
   },
   "source": [
    "**Exercise:** Show an image of your dataset, with its corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1637772688345,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "rzKS4yht6CNB",
    "outputId": "dace9635-af76-4596-c812-57a5a2c72d97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  y = [1] ==> cat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index =7  # index of image to be shown \n",
    "# plot here \n",
    "# print the corresponding label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGTnyZmLBJeV"
   },
   "source": [
    "**Exercise:**\n",
    "Find the values for these variables:\n",
    "- m_train = ?  (number of training examples)\n",
    "- m_test = ? (number of test examples)\n",
    "- num_px = ? height or  width of an image\n",
    "- Print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1637772688346,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "mAH6mUn6A_Wf",
    "outputId": "013dd312-9b09-4c55-f3c5-ac6ece12100b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape: (209, 64, 64, 3)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x shape: (50, 64, 64, 3)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB_INELHB-K2"
   },
   "source": [
    "###Reshape images,, why ?\n",
    "\n",
    "Remember that images are of shape (num_px, num_px, 3). Because we are going to uses full-connected 1D NN see figure, you have to reshape images into shape (num_px $*$ num_px $*$ 3, 1) which is numpy-array.\n",
    "So that, after this reshaping, you get a dataset of numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns.\n",
    "\n",
    "<img src=https://raw.githubusercontent.com/mymehio/test/master/LogReg_kiank.png width=\"550\" height = 350>\n",
    "\n",
    "**Exercise:**\n",
    " Reshape the training and test datasets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px $*$ num_px $*$ 3, 1).\n",
    "\n",
    "A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$*$c$*$d, a) is to use:\n",
    "\n",
    "X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1637772688346,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "SyJrR8I6B9e2",
    "outputId": "50bf68db-e78d-497c-f684-f3254305f626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (12288, 209)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x_flatten shape: (12288, 50)\n",
      "test_set_y shape: (1, 50)\n",
      "sanity check after reshaping: [17 31 56 22 33]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T\n",
    "\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWTDiH4bFSBq"
   },
   "source": [
    "### Dataset Normalization\n",
    "One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).\n",
    "\n",
    "Let's standardize our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcRTB8zT-2U-"
   },
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten / 255.    #why \n",
    "test_set_x = test_set_x_flatten / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkMVzAEhGJ07"
   },
   "source": [
    "#**Building the parts of NN Architecture**\n",
    "\n",
    "### **1) Implement the sigmoid Function**\n",
    "First, You will begin by coding the sigmoid function by computing sigmoid( z) = 1/1+exp(-z), Where z = wx+b . Use np.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnNXN6GnG6Pv"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "   # your code here\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1637772688348,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "iSUvpTRTHKuz",
    "outputId": "2f337e8a-ba48-4cbf-d1cf-cbd26c42c62c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([1, 2]) = [0.73105858 0.88079708]\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([1, 2]) = \" + str(sigmoid(np.array([1,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXoBFpCuHu3A"
   },
   "source": [
    "### **2) Initialize the model parameters**\n",
    "Now, you will continue by initializing the model parameters. The model parameters are the weights (w) and bias (b) with x as the input feature.\n",
    "\n",
    " w â€” initialized vector of shape (dim, 1)\n",
    " b â€” initialized scalar (corresponds to the bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzVK3yCdHPlP"
   },
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "     \n",
    "     return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1637772688723,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "duXq9MSOIWFe",
    "outputId": "d439906f-9c3c-49df-dfef-990ae6850a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.]\n",
      " [0.]]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98tELRPiIgEr"
   },
   "source": [
    "### **3) Implement forward and backward propagation for learning the parameters**\n",
    "\n",
    "This step is to implement the function called propagate() that learns the parameters w, b, and find y from x by computing the loss function (forward) and its gradient (backward).\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "###Forward Propagation:\n",
    "\n",
    "- You get X\n",
    "- You compute $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- You calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "Here are the two formulas you will be using:\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T$$$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})$$\n",
    "\n",
    "\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "```\n",
    "Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AFpwpWcIYEG"
   },
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    y_hat = sigmoid(np.dot(w.T, X) + b)  # compute activation\n",
    "    cost = -1/m*(np.sum(?*np.log(?) + ? ))   # compute cost\n",
    "   \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    dw = 1/m*(np.dot(?, ((y_hat-Y).T)))\n",
    "    db = 1/m*(np.sum(y_hat-?))\n",
    "  \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1637772688724,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "NUyBWeGAKqjE",
    "outputId": "2ee19fe8-be3a-41a8-a417-7073df40095a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = [[0.99845601]\n",
      " [2.39507239]]\n",
      "db = 0.001455578136784208\n",
      "cost = 5.801545319394553\n"
     ]
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoKV6yAxsqU-"
   },
   "source": [
    "### **4) Optimization**\n",
    "\n",
    "- You have initialized your parameters.\n",
    "- You are also able to compute a loss function and its gradient\n",
    "- Now, you want to update repeatly the parameters using gradient descent .\n",
    "\n",
    "\n",
    "**Exercise:** \n",
    "\n",
    "Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the loss function $J$. \n",
    "\n",
    "For a parameter $\\theta$, the update rule is $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, where $\\alpha$ is the learning rate.\n",
    "\n",
    "\n",
    "Tips: \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "  \n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the loss and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wV6LvwKWuDIC"
   },
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \n",
    "    losses = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, loss = ?    # which function calculates the loss an grads ? \n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update learning rules \n",
    "       \n",
    "        w = ?\n",
    "        b = ?\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            losses.append(loss)\n",
    "        \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"loss after iteration %i: %f\" %(i, loss))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1637772688725,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "5rZnBzuhv7CF",
    "outputId": "738be33a-b335-450c-9352-243ba01527bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.19033591]\n",
      " [0.12259159]]\n",
      "b = 1.9253598300845747\n",
      "dw = [[0.67752042]\n",
      " [1.41625495]]\n",
      "db = 0.21919450454067652\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiCFEcylx0qt"
   },
   "source": [
    "**Exercise:**\n",
    "\n",
    "The previous function will output the learned w and b. \n",
    "\n",
    "Which means that you have already a learned model, and it's able to use w and b to predict the labels for a dataset X as input.  \n",
    "Implement the predict() function. There are two steps to computing predictions:\n",
    "\n",
    "- Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "- Convert the entries of $A$ into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector Y_prediction. If you wish, you can use an if/else statement in a for loop (though there is also a way to vectorize this).\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "\n",
    "```\n",
    "Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJIyFUzYwM3M"
   },
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    m = X.shape[1] # m becomes the num of entries after reshape\n",
    "    # your code here\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1637772688726,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "VSEeGRzVzDEM",
    "outputId": "6f2a77b0-96d7-4d2b-bfbf-72935f0b7f8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1637772688726,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "V-3-PnVzAAPy",
    "outputId": "9c73844f-8d9d-4558-b0ca-637d1fedf9db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(w.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GCQBC4_Geng"
   },
   "source": [
    "You have already done: \n",
    "\n",
    "- Initialize (w,b)\n",
    "- Optimize the loss iteratively to learn parameters (w,b):\n",
    "- computing the loss function and its gradient\n",
    "- updating the parameters using gradient descent\n",
    " - Use the learned (w,b) to predict the labels for a given set of examples\n",
    "Now Let's merge all together\n",
    "\n",
    "## **5) Putting it all together to form a model**\n",
    "Now that you have our sigmoid function, loss function, and gradient descent, we will then combine everything into one single model and use this model to predict whether an image is a cat or non-cat\n",
    "\n",
    "\n",
    "**Exercise:** Implement the model function. Use the following notation:\n",
    "\n",
    "- Y_prediction_test for your predictions on the test set\n",
    "- Y_prediction_train for your predictions on the train set\n",
    "- w, costs, grads for the outputs of optimize()\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "```\n",
    "Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "error",
     "timestamp": 1637772688729,
     "user": {
      "displayName": "Franck Tchouanga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpa4lyMwfa-KUju1ZYe9_Xu8E5BkJcjuOkeuJtTQ=s64",
      "userId": "08976604899167737531"
     },
     "user_tz": -60
    },
    "id": "JbbA7pVSFrVb",
    "outputId": "69f0ba33-7a38-4a01-f3f4-3abd5fce6dd7"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-f96bf745489d>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    w, b = ?\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \n",
    "    w, b = ?\n",
    "    #print('shape of weights', w.shape)\n",
    "    # Gradient descent\n",
    "    parameters, grads, costs = ?\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = ?\n",
    "    Y_prediction_train = ?\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(?) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(?) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChHyR59fIrzX"
   },
   "source": [
    "Call the function on the real data (train_set_x, train_set_y, test_set_x, test_set_y) to train your model.\n",
    "itrerations = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuSg_pwQdkeE"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4858,
     "status": "ok",
     "timestamp": 1637156395500,
     "user": {
      "displayName": "Yasser ALMEHIO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij0wzGqMNjD5sCRLAXEatSpiC6bdV_bpGmoAtxFQ=s64",
      "userId": "17884573495595278135"
     },
     "user_tz": -60
    },
    "id": "QIoXWL7IdlDq",
    "outputId": "d73f2482-5ce4-49a0-aa4a-cf39f8ef711e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 99.52153110047847 %\n",
      "test accuracy: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.01, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z1udjZZOGMh"
   },
   "source": [
    "* Try different: learning rate values, number of iterations, and see the results onf test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gp18nOgGOF2W"
   },
   "outputs": [],
   "source": [
    "train_set_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3R7TrthaIn9y"
   },
   "outputs": [],
   "source": [
    "index = 9\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "print (\"y = \" + str(test_set_y[0,index]) + \", you predicted that it is a \\\"\" + classes[np.int(?['Y_prediction_test'][0,index])].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szzaKUsrOXEL"
   },
   "source": [
    "Let's plot the curve of loss function during the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkLJVBG9J5bY"
   },
   "outputs": [],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost/loss')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJcYjJg0SCMi"
   },
   "source": [
    "## **Further Exercises**\n",
    "\n",
    "**Reminder:** In order for Gradient Descent to work, you must choose the learning rate wisely. The learning rate $\\alpha$ determines how rapidly we update the parameters. If the learning rate is too large we may \"overshoot\" the optimal value. Similarly, if it is too small we will need too many iterations to converge to the best values. That's why it is crucial to use a well-tuned learning rate.\n",
    "\n",
    "* Let's compare the learning curve of your model with several choices of learning rates.\n",
    "* Feel free also to try different values than the three we have initialized the learning_rates variable to contain, and see what happens.\n",
    "\n",
    "* Please put your comments and interpretations after seeing the results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1Oe2O1bS0zv"
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    #suggest your code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_w3tiKUTeca"
   },
   "source": [
    "**Interpretation:**\n",
    "\n",
    "-put your interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWcKyQZ0VfW8"
   },
   "source": [
    "## **Test with your own image** \n",
    "1. Add your image to this Notebook's directory, in the \"images\" folder (take or download one)\n",
    "2. choose your image's name in the following code\n",
    "3. Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58H_hmMmTVCK"
   },
   "outputs": [],
   "source": [
    "import cv2    #use opencv library to read and resize the image\n",
    "my_image = \"cat.jpg\"   \n",
    "\n",
    "fname =  my_image\n",
    "image = cv2.imread(fname,cv2.IMREAD_UNCHANGED)\n",
    "#normalize and resize your original image\n",
    "your_image = #normalize it\n",
    "your_image =  #resize it\n",
    "#display it\n",
    "\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], your_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZRRFb2AZSn7"
   },
   "source": [
    "**Bibliography:**\n",
    "\n",
    "http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgyHvJ489p9-"
   },
   "source": [
    "# Exercise \n",
    "## Build Your Model using Keras library and tensorflow as backend\n",
    "\n",
    "[Keras is an open-source software library](https://keras.io/getting_started/) that provides a Python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library.\n",
    "\n",
    "Up until version 2.3, Keras supported multiple backends, including TensorFlow, Microsoft Cognitive Toolkit, Theano, and PlaidML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-jlRtgD9yfF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oi9zTvYJ93F6"
   },
   "source": [
    "### Load Data from hdf file\n",
    "- \n",
    "\n",
    "1.   Use the same method of above\n",
    "2. List all keys available in the loaded data set \n",
    "\n",
    "```\n",
    "train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
    "list(train_dataset.keys())\n",
    "```\n",
    "3.   Use a a percent of train dataset to validate with during the training, as\n",
    "\n",
    "```\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
    "train_set_x_orig = ? # your train set of images  \n",
    "train_set_y_orig = ? # your train set labels\n",
    "\n",
    "\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(train_set_x_orig,train_set_y_orig,test_size = 0.1)\n",
    "```  \n",
    "\n",
    "4.   Visualize a histogram of how many images are cat and non-cat, use seaborn library\n",
    "\n",
    "```\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(list(train_set_y_orig),palette='twilight')\n",
    "```\n",
    "4.  Build the model using keras API \n",
    "\n",
    "```\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape = ?)) # this layer is to put 3D image into a 1D vector\n",
    "\n",
    "model.add(layers.Dense(?,activation='relu'))# dense layer is full connected layer\n",
    "model.add(layers.Dense(?,activation='sigmoid')) # why sigmoid ?\n",
    "\n",
    "- Please provide your own model architecture ( N layers) and justify your choice.\n",
    "- Please provide your interpretation of sigmoid choice.\n",
    "```\n",
    "5. To train the model, use *compile function* it needs to specify the loss function and an optimizer (to learn more about it in the next sessions). Then Use *fit function*  to start the learning process by the model \n",
    "\n",
    "\n",
    "```\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,validation_data = (X_val, Y_val),epochs=100, batch_size=16)\n",
    "\n",
    "adam*: is an advanced version of gradient descent, you can use it as is for now. \n",
    "\n",
    "Why using binary_crossentropy ?\n",
    "```\n",
    "6. Plot Loss and accuracy curves of training and validation dataset \n",
    "\n",
    "\n",
    "```\n",
    "acc = modelk.history.history['accuracy']\n",
    "val_acc = modelk.history.history['val_accuracy']\n",
    "loss = modelk.history.history['loss']\n",
    "val_loss = modelk.history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label= 'Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label= 'Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "## then plot the loss curves \n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snwZl9wWAlYr"
   },
   "source": [
    "## How tesing your model\n",
    "\n",
    "1. Load your test dataset\n",
    "\n",
    "\n",
    "```\n",
    "file = 'test_catvnoncat.h5'\n",
    "test_dataset = h5py.File(file, 'r')\n",
    "group_key = list(test_dataset.keys())\n",
    "\n",
    "\n",
    "test_set_x_orig = ? # your test of images\n",
    "test_set_y_orig = ? # your test set labels\n",
    "```\n",
    "\n",
    "2. prdict the test data with the trained model\n",
    "\n",
    "\n",
    "```\n",
    "predk = modelk.predict(test_set_x_orig)\n",
    "predictions= []\n",
    "for i in predk:\n",
    "    if i>=0.5:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "```\n",
    "\n",
    "3. Evaluate the accuracy and the loss using testing dataset\n",
    "\n",
    "\n",
    "```\n",
    "loss, acc = modelk.evaluate(test_set_x_orig, test_set_y_orig,\n",
    "                            batch_size=32)\n",
    "print('Test score:', loss)\n",
    "print('Test accuracy:', acc)\n",
    "```\n",
    "\n",
    "\n",
    "4. Test with your own image\n",
    "```\n",
    "As explained before, follow the same steps please\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pnEZAcSBlvx"
   },
   "source": [
    "Please, Use your own notebook to implement and complete your work, then please email me the following elements:\n",
    "\n",
    "* a copy pdf of your notebook\n",
    "* share me your notebook via my address mymehio@gmail.com\n",
    "* deadline: 24/11 11:59 PM"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1duaX69OiWvMkE27RvN2NHlP1ywretybW",
     "timestamp": 1637154834241
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
